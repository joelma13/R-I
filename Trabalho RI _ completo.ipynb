{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\joelma.fatima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\joelma.fatima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consulta: educação\n",
      "Resultados:\n",
      "https://ouropreto.ifmg.edu.br/ouropreto: -3.0757749812275272\n",
      "https://brasilescola.uol.com.br: -24.60619984982022\n",
      "https://www.gov.br/inep/pt-br/areas-de-atuacao/avaliacao-e-exames-educacionais/enem: -172.24339894874163\n",
      "Precision: 0.3333333333333333, Recall: 1.0\n",
      "\n",
      "Consulta: enem\n",
      "Resultados:\n",
      "https://ouropreto.ifmg.edu.br/ouropreto: -5.957850310475219\n",
      "https://www.gov.br/inep/pt-br/areas-de-atuacao/avaliacao-e-exames-educacionais/enem: -62.55742825998983\n",
      "https://brasilescola.uol.com.br: -107.2413055885539\n",
      "Precision: 0.3333333333333333, Recall: 1.0\n",
      "\n",
      "Consulta: educação e enem\n",
      "Resultados:\n",
      "https://ouropreto.ifmg.edu.br/ouropreto: -9.033625291702746\n",
      "https://brasilescola.uol.com.br: -131.8475054383741\n",
      "https://www.gov.br/inep/pt-br/areas-de-atuacao/avaliacao-e-exames-educacionais/enem: -234.80082720873162\n",
      "Precision: 0.3333333333333333, Recall: 1.0\n",
      "\n",
      "Consulta: educação ou enem\n",
      "Resultados:\n",
      "https://ouropreto.ifmg.edu.br/ouropreto: -9.033625291702746\n",
      "https://brasilescola.uol.com.br: -131.8475054383741\n",
      "https://www.gov.br/inep/pt-br/areas-de-atuacao/avaliacao-e-exames-educacionais/enem: -234.80082720873162\n",
      "Precision: 0.3333333333333333, Recall: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from urllib.parse import urljoin\n",
    "from collections import defaultdict\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import math\n",
    "\n",
    "class Coletor:\n",
    "    def __init__(self):\n",
    "        self.urls = []\n",
    "\n",
    "    def adicionar_url(self, url):\n",
    "        self.urls.append(url)\n",
    "\n",
    "    def extrair_texto(self, html):\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        texto = soup.get_text(separator=' ')\n",
    "        return texto\n",
    "\n",
    "    def coletar(self):\n",
    "        textos = {}\n",
    "        for url in self.urls:\n",
    "            response = requests.get(url)\n",
    "            if response.status_code == 200:\n",
    "                html = response.text\n",
    "                texto = self.extrair_texto(html)\n",
    "                textos[url] = texto\n",
    "        return textos\n",
    "\n",
    "class Indexador:\n",
    "    def __init__(self):\n",
    "        self.indice_invertido = defaultdict(list)\n",
    "        self.stopwords = set(stopwords.words('portuguese'))\n",
    "        self.stopwords.update(string.punctuation)\n",
    "\n",
    "    def indexar(self, textos):\n",
    "        for url, texto in textos.items():\n",
    "            tokens = word_tokenize(texto.lower())\n",
    "            for token in tokens:\n",
    "                if token not in self.stopwords:\n",
    "                    self.indice_invertido[token].append(url)\n",
    "\n",
    "    def calcular_tfidf(self, num_documentos):\n",
    "        tfidf = {}\n",
    "        for termo, ocorrencias in self.indice_invertido.items():\n",
    "            idf = math.log(num_documentos / len(ocorrencias))\n",
    "            tfidf[termo] = idf\n",
    "        return tfidf\n",
    "\n",
    "class Buscador:\n",
    "    def __init__(self, indice_invertido, tfidf):\n",
    "        self.indice_invertido = indice_invertido\n",
    "        self.tfidf = tfidf\n",
    "\n",
    "    def buscar(self, consulta):\n",
    "        tokens_consulta = word_tokenize(consulta.lower())\n",
    "        scores = defaultdict(float)\n",
    "        for token in tokens_consulta:\n",
    "            if token in self.indice_invertido:\n",
    "                idf = self.tfidf.get(token, 0)\n",
    "                for documento in self.indice_invertido[token]:\n",
    "                    scores[documento] += idf\n",
    "        resultados = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "        return resultados\n",
    "\n",
    "class Avaliador:\n",
    "    def __init__(self, relevantes):\n",
    "        self.relevantes = relevantes\n",
    "\n",
    "    def avaliar(self, resultados):\n",
    "        relevantes_retrieved = 0\n",
    "        relevantes_totais = len(self.relevantes)\n",
    "        for url, _ in resultados:\n",
    "            if url in self.relevantes:\n",
    "                relevantes_retrieved += 1\n",
    "        precisao = relevantes_retrieved / len(resultados) if len(resultados) > 0 else 0\n",
    "        revocacao = relevantes_retrieved / relevantes_totais\n",
    "        return precisao, revocacao\n",
    "\n",
    "# Exemplo de uso\n",
    "if __name__ == \"__main__\":\n",
    "    urls_coleta = [\n",
    "        \"https://www.gov.br/inep/pt-br/areas-de-atuacao/avaliacao-e-exames-educacionais/enem\",\n",
    "        \"https://ouropreto.ifmg.edu.br/ouropreto\",\n",
    "        \"https://brasilescola.uol.com.br\"\n",
    "    ]\n",
    "    consultas = [\"educação\", \"enem\", \"educação e enem\", \"educação ou enem\"]\n",
    "\n",
    "    coletor = Coletor()\n",
    "    for url in urls_coleta:\n",
    "        coletor.adicionar_url(url)\n",
    "    textos_coletados = coletor.coletar()\n",
    "\n",
    "    indexador = Indexador()\n",
    "    indexador.indexar(textos_coletados)\n",
    "    tfidf = indexador.calcular_tfidf(len(textos_coletados))\n",
    "\n",
    "    buscador = Buscador(indexador.indice_invertido, tfidf)\n",
    "\n",
    "    relevantes = [\"https://www.gov.br/inep/pt-br/areas-de-atuacao/avaliacao-e-exames-educacionais/enem\"]\n",
    "    avaliador = Avaliador(relevantes)\n",
    "\n",
    "    for consulta in consultas:\n",
    "        resultados = buscador.buscar(consulta)\n",
    "        precisao, revocacao = avaliador.avaliar(resultados)\n",
    "        print(f\"Consulta: {consulta}\")\n",
    "        print(\"Resultados:\")\n",
    "        for url, score in resultados:\n",
    "            print(f\"{url}: {score}\")\n",
    "        print(f\"Precision: {precisao}, Recall: {revocacao}\")\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando  o modelo TF-IFF para o processamento de consultas e para ranqueamento de resultados. \n",
    "Implemnetação da avaliação das consultas usando métricas de precisão e revocação. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados da consulta:\n",
      "Documento 1: 0.5500248858857211\n",
      "Documento 0: 0.3116940163436369\n",
      "Documento 2: 0.24985512660870635\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "class IndexadorTFIDF:\n",
    "    def __init__(self):\n",
    "        self.documentos = []\n",
    "        self.tf_idf_model = None\n",
    "        self.stopwords = set(stopwords.words('portuguese'))\n",
    "\n",
    "    def indexar(self, documentos):\n",
    "        self.documentos = documentos\n",
    "        corpus = [' '.join([token for token in word_tokenize(doc['texto'].lower()) if token not in self.stopwords]) for doc in documentos]\n",
    "        self.tf_idf_model = TfidfVectorizer()\n",
    "        self.tf_idf_model.fit(corpus)\n",
    "\n",
    "    def processar_consulta(self, consulta):\n",
    "        consulta = ' '.join([token for token in word_tokenize(consulta.lower()) if token not in self.stopwords])\n",
    "        consulta_tf_idf = self.tf_idf_model.transform([consulta])\n",
    "        scores = cosine_similarity(consulta_tf_idf, self.tf_idf_model.transform([doc['texto'] for doc in self.documentos]))[0]\n",
    "        resultados = sorted(list(enumerate(scores)), key=lambda x: x[1], reverse=True)\n",
    "        return resultados\n",
    "\n",
    "# Exemplo de uso\n",
    "if __name__ == \"__main__\":\n",
    "    # Exemplo de documentos e consulta\n",
    "    documentos = [\n",
    "        {'texto': 'Este é um exemplo de documento sobre análise de sentimentos.'},\n",
    "        {'texto': 'Neste documento, falamos sobre processamento de linguagem natural e indexação.'},\n",
    "        {'texto': 'A análise de sentimentos é uma área importante da mineração de textos.'}\n",
    "    ]\n",
    "    consulta = 'análise de sentimentos e processamento de linguagem natural'\n",
    "\n",
    "    # Indexar documentos\n",
    "    indexador = IndexadorTFIDF()\n",
    "    indexador.indexar(documentos)\n",
    "\n",
    "    # Processar consulta\n",
    "    resultados = indexador.processar_consulta(consulta)\n",
    "\n",
    "    print(\"Resultados da consulta:\")\n",
    "    for idx, score in resultados:\n",
    "        print(f\"Documento {idx}: {score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com esses documentos e consulta, o resultado da consulta deve priorizar o segundo documento, que contém mais termos relevantes para a consulta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo de documentos e consulta\n",
    "documentos = [\n",
    "    {'texto': 'Este é um exemplo de documento sobre análise de sentimentos.'},\n",
    "    {'texto': 'Neste documento, falamos sobre processamento de linguagem natural e indexação.'},\n",
    "    {'texto': 'A análise de sentimentos é uma área importante da mineração de textos.'}\n",
    "]\n",
    "\n",
    "consulta = 'processamento de linguagem natural e mineração de textos'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "este caso, o resultado da consulta deve priorizar o segundo e terceiro documentos, pois eles contêm termos relevantes para a consulta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo de documentos e consulta\n",
    "documentos = [\n",
    "    {'texto': 'Este é um exemplo de documento sobre aprendizado de máquina.'},\n",
    "    {'texto': 'Aqui discutimos sobre redes neurais e algoritmos de aprendizado.'},\n",
    "    {'texto': 'A aprendizagem profunda é uma técnica avançada de aprendizado de máquina.'}\n",
    "]\n",
    "\n",
    "consulta = 'aprendizado de máquina e redes neurais'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados da consulta:\n",
      "Documento 1: 0.5500248858857211\n",
      "Documento 0: 0.3116940163436369\n",
      "Documento 2: 0.24985512660870635\n"
     ]
    }
   ],
   "source": [
    "# Exemplo de uso\n",
    "if __name__ == \"__main__\":\n",
    "    # Exemplo de documentos e consulta\n",
    "    documentos = [\n",
    "        {'texto': 'Este é um exemplo de documento sobre análise de sentimentos.'},\n",
    "        {'texto': 'Neste documento, falamos sobre processamento de linguagem natural e indexação.'},\n",
    "        {'texto': 'A análise de sentimentos é uma área importante da mineração de textos.'}\n",
    "    ]\n",
    "    consulta = 'análise de sentimentos e processamento de linguagem natural'\n",
    "\n",
    "    # Indexar documentos\n",
    "    indexador = IndexadorTFIDF()\n",
    "    indexador.indexar(documentos)\n",
    "\n",
    "    # Processar consulta\n",
    "    resultados = indexador.processar_consulta(consulta)\n",
    "\n",
    "    print(\"Resultados da consulta:\")\n",
    "    for idx, score in resultados:\n",
    "        print(f\"Documento {idx}: {score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frase: 'Eu amo esse filme! É incrível.' - Sentimento: neutro\n",
      "Frase: 'Que dia terrível... Não consigo lidar com isso.' - Sentimento: neutro\n",
      "Frase: 'O tempo está bom lá fora.' - Sentimento: neutro\n",
      "Frase: 'Isso é tão legal!' - Sentimento: positivo\n",
      "Frase: 'Não gosto desse produto. Foi uma compra ruim.' - Sentimento: neutro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\joelma.fatima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# Baixar recursos necessários do NLTK (execute apenas uma vez)\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Inicializar o analisador de sentimentos\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Função para interpretar o score de sentimento\n",
    "def interpretar_sentimento(score):\n",
    "    if score['compound'] >= 0.05:\n",
    "        return \"positivo\"\n",
    "    elif score['compound'] <= -0.05:\n",
    "        return \"negativo\"\n",
    "    else:\n",
    "        return \"neutro\"\n",
    "\n",
    "# Frases de exemplo\n",
    "frases = [\n",
    "    \"Eu amo esse filme! É incrível.\",\n",
    "    \"Que dia terrível... Não consigo lidar com isso.\",\n",
    "    \"O tempo está bom lá fora.\",\n",
    "    \"Isso é tão legal!\",\n",
    "    \"Não gosto desse produto. Foi uma compra ruim.\"\n",
    "]\n",
    "\n",
    "# Analisar o sentimento de cada frase\n",
    "for frase in frases:\n",
    "    score = sia.polarity_scores(frase)\n",
    "    sentimento = interpretar_sentimento(score)\n",
    "    print(f\"Frase: '{frase}' - Sentimento: {sentimento}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
